# 🧠 My ML Journey Step 2: Gathering Data 🚀

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python)
![Pandas](https://img.shields.io/badge/Pandas-1.6%2B-brightgreen?style=for-the-badge&logo=pandas)
![SQL](https://img.shields.io/badge/SQL-Structured%20Query%20Language-blue?style=for-the-badge&logo=mysql)
![JSON](https://img.shields.io/badge/JSON-Files-yellow?style=for-the-badge&logo=json)

---

## 🔄 Where I Am in the ML Workflow

✅ **Step 1 — Framing the Problem**  
*I learned how to define ML problems clearly and identify what I want to predict.*

🟢 **Step 2 — Gathering Data (current focus)**  
*This step is all about collecting data from multiple sources:*
- Flat files (**CSV**, **JSON**)  
- Databases (**SQL**, **SSMS**)  
- APIs  
- Web scraping (**BeautifulSoup, Requests**)  

⏳ **Step 3 — Data Cleaning & Preparation (coming soon...)**  

> 💡 *Tip:* The better the data you collect, the easier the modeling steps will be later. Garbage in → garbage out!  

---

## 🛠️ Tools in My Toolkit
- 🐍 **Python 3** — Main programming language  
- 🐼 **Pandas** — Data handling & analysis  
- 🗄️ **SQL (SQLite3 + SSMS)** — Database querying  
- 📄 **JSON** — File format handling  
- 🌐 **Requests & BeautifulSoup4** — Web scraping  

> ✨ *I’m learning to gather data in multiple formats so I’m fully prepared for the next ML steps.*  

---

## 🎯 Why I’m Doing This
Before I can **clean, model, or deploy**, I must **master the art of gathering data**.  

> 📝 *This repo is my sandbox for practicing data collection. It’s where I experiment, make mistakes, and learn!*  

---

## 📌 Run the Code
1. **Clone the repo:**
   ```bash
   git clone https://github.com/Sidra-009/your-repo-name.git
Move into the folder:

bash
Copy code
cd your-repo-name
Run the practice files step by step:

bash
Copy code
python day1_csv.py


💬 Every line of code here is a step closer to becoming a confident ML practitioner.

⭐ If you find this repo helpful or inspiring, give it a star!

Author: Sidra Bibi
